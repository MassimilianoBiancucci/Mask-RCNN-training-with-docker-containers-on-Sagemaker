{
 "cells": [
  {
   "source": [
    "## Sagemaker dummy example\n",
    "<p>In this example is launched a dummy container using spot instances, to test what's the behavior of the aws Sagemaker with docker containers, and what's the behaviour of the container whene it is terminated by aws due to lack of spot resources.</p>\n",
    "<p>In this example is simulated by a dummy python script (into the container) that performs similar actions that a normal training script with tensorflow or other framework should do, more specificaly:\n",
    "\n",
    "- Fake checkpoints are written in txt format in the folder /opt/ml/checkpoints/.\n",
    "\n",
    "- Fake tensorboard records are written every 20 seconds into the folder /opt/ml/output/tensorboard/, for check the real-time prensence into the s3 bucket folder  specified.\n",
    "\n",
    "- Furthermore the tree command is executed in the path /opt/ml/ for inspect the folder structure created by sagemaker, and the result is stored in the /opt/output/ data/ folder as a txt file.\n",
    "</p> "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e06426f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.debugger import TensorBoardOutputConfig"
   ]
  },
  {
   "source": [
    "#### In this section is recovered the Sagemaker bucket generated by default from the service"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf426bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket generated by sagemacker:sagemaker-eu-west-1-011827850615\n",
      "output folder: s3://sagemaker-eu-west-1-011827850615/output\n"
     ]
    }
   ],
   "source": [
    "# default sagemaker bucket name request \n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "sagemaker_default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(\"bucket generated by sagemacker:\" + sagemaker_default_bucket)"
   ]
  },
  {
   "source": [
    "############################  JOB NAME  ####################################\n",
    "\n",
    "# job-name definition:\n",
    "# every multi-job session of training jobs is characterized by a base-job-name\n",
    "# the job-name on the contrary is the identifier of the single training job.\n",
    "# The job-name must be different for each training job and should be used to\n",
    "# divide the results of different training jobs into specific folders.\n",
    "job_name = 'test-11'"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#### In this section are defined all the nedeed variables that specify the paths to s3 buckets for the inputs and outputs data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98fc4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################   INPUTS  ####################################\n",
    "\n",
    "# repositroy ECR containing the docker image configured to be executed by Sagemaker\n",
    "ecr_container_uri = \"011827850615.dkr.ecr.eu-west-1.amazonaws.com/test_repo:latest\"\n",
    "\n",
    "# s3 path containing the dataset needed for training the model\n",
    "dataset_bucket = \"s3://datsetsbucket/isic2018/test_dataset/\"\n",
    "\n",
    "# s3 path containing the model with pretrained weights, in the next example in this folder would be\n",
    "# stored the Mask R-CNN model trained on COCO. \n",
    "model_bucket = 's3://cermodelbucket'\n",
    "\n",
    "\n",
    "############################  OUTPUTS  ####################################\n",
    "\n",
    "# s3 path where are stored the results of the instance profiler and any other data saved during the training in the folder /opt/ml/output/data/\n",
    "output_path = f's3://{sagemaker_default_bucket}/output'\n",
    "\n",
    "# s3 path where are stored the checkpoints of the training proces\n",
    "checkpoints_path = f'{output_path}/{job_name}/checkpoints'\n",
    "\n",
    "# Definition of s3 target bucket folder for the tensorboard outputs and container folder where the tensorboard record must to be placed.\n",
    "# it's possible to place the tensorboard output in other places but sagemaker copy that records into '/opt/ml/output/tensorboard' so we decide to\n",
    "# put the records directly in there.\n",
    "# Note: in the path 's3://testtflogs/logs' the recors are divided into folders related to the job-name in this example the output of tensorboard\n",
    "# should be fine in 's3://testtflogs/logs/test-11'\n",
    "tensorboard_output_config = TensorBoardOutputConfig(\n",
    "    s3_output_path='s3://testtflogs/logs',\n",
    "    container_local_output_path='/opt/ml/output/tensorboard'\n",
    ")\n"
   ]
  },
  {
   "source": [
    "#### In this section are recovered the execution role ARN associated to this notebook, that will be passed to the estimator for launching the training job, be sure to give permissions to use other buckets to this role, otherwise it will only be possible to use buckets starting with the sagemaker keyword, in this case the permission is needed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "445b7197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::011827850615:role/service-role/AmazonSageMaker-ExecutionRole-20210522T125188\n"
     ]
    }
   ],
   "source": [
    "# getting the execution role of this instance of sagemaker notebook\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "source": [
    "#### In this sections are defined the hyperparameters , this values are passed to the estimator definitions and would be reachable from the trainning script in the container as commandline arguments, or like environment variables whit this notation SM\\_HP_{hyperparameter_name}, es. SM_HP_HP1 or SM_HP_BATCH in this case"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5e29ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters definition\n",
    "hyperparameters = {\n",
    "    'hp1': 'value_x',\n",
    "    'hp2': 314,\n",
    "    'hp3': 3.1415,\n",
    "    'batch': 7\n",
    "}"
   ]
  },
  {
   "source": [
    "#### This is the key function of the script, in there are configured al the training job parameters, are passed all the path that was defined earlier, the hyperparameters and are defined many settings relative to the type of machine used for the job, and in witch mode should run.\n",
    "\n",
    "#### More specificaly we chose to run in spot mode (use_spot_instances = True), in this mode the cost of the training goes down from 50% to 80% depending on the instance type chosen and by the availability of the machine, this modality enable aws to sell at lower price unused compute capability in the cloud and can stop your application if someone need this machine in on-demand mode (without any discount).\n",
    "\n",
    "#### In "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1aaf3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_test = sagemaker.estimator.Estimator(\n",
    "    image_uri    = ecr_container_uri, # container image \n",
    "    role         = role, # role of sagemaker notebook instance\n",
    "    instance_count = 1, # numero di instanze da lanciare\n",
    "    #train_instance_type=\"local\",  # use local mode\n",
    "    instance_type = 'ml.m5.large', # tipo di macchina da lanciare\n",
    "    volume_size  = 50, # dimensione in GB del volume associato all'istanza da lanciare\n",
    "    max_run      = 10*3600, # massimo numero di secondi di addestramento prima della terminazione forzata dell'instanza\n",
    "    output_path  = output_path, # destinazione bucket s3 per file contenuti in \n",
    "    #base_job_name=\"training-test\", # prefix for the trainng job name, if not specified generated automatically\n",
    "    hyperparameters = hyperparameters, # training job hyperparameters\n",
    "    model_uri    = model_bucket, # percorso s3 o del notebook in cui è contenuti i modelli, e che verranno copiati nel canale corrispondente del container      (sovrascrivibile da model_channel_name)\n",
    "    #model_channel_name = 'model', # nome del canale in cui vengono salvati i modelli contenuti in model_uri\n",
    "    #metric_definitions = , # dict contenete un dict {\"<nome metrica>\":\"<regex per l'estrazione dai logs>\", ...}\n",
    "    use_spot_instances = True, # flag di abilitazione istanza spot\n",
    "    max_wait = 24*3600, # massimo un giorno di attesa per la riattivazione della macchina\n",
    "    checkpoint_s3_uri = checkpoints_path, # percorso s3 di destinazione dei chekpoints\n",
    "    #checkpoint_local_path = '', # default: '/opt/ml/checkpoints'\n",
    "    #rules = ; # SageMaker Debugger rules\n",
    "    tensorboard_output_config = tensorboard_output_config #\n",
    "    #environment = {}, # dict contente le variabili d'ambiente che devono essere settate\n",
    "    #max_retry_attempts =  #numero massimo di tentativi di ripristino del docker se il job non viene completato\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e24081b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-22 22:30:02 Starting - Starting the training job...\n",
      "2021-05-22 22:30:26 Starting - Launching requested ML instancesProfilerReport-1621722602: InProgress\n",
      "......\n",
      "2021-05-22 22:31:26 Starting - Preparing the instances for training...\n",
      "2021-05-22 22:31:52 Downloading - Downloading input data...\n",
      "2021-05-22 22:32:26 Training - Downloading the training image...\n",
      "2021-05-22 22:32:48 Training - Training image download completed. Training in progress.\u001b[34m2021-05-22 22:32:47,914 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-22 22:32:47,915 sagemaker-training-toolkit INFO     Failed to parse hyperparameter hp1 value value_x to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2021-05-22 22:32:50,947 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-22 22:32:50,948 sagemaker-training-toolkit INFO     Failed to parse hyperparameter hp1 value value_x to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2021-05-22 22:32:50,959 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-22 22:32:50,960 sagemaker-training-toolkit INFO     Failed to parse hyperparameter hp1 value value_x to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2021-05-22 22:32:50,969 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"dataset\": \"/opt/ml/input/data/dataset\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"hp1\": \"value_x\",\n",
      "        \"hp3\": 3.1415,\n",
      "        \"hp2\": 314\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"dataset\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"test-11\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"hp1\":\"value_x\",\"hp2\":314,\"hp3\":3.1415}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"dataset\",\"model\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"dataset\":\"/opt/ml/input/data/dataset\",\"model\":\"/opt/ml/input/data/model\"},\"current_host\":\"algo-1\",\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"hp1\":\"value_x\",\"hp2\":314,\"hp3\":3.1415},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"test-11\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--hp1\",\"value_x\",\"--hp2\",\"314\",\"--hp3\",\"3.1415\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_DATASET=/opt/ml/input/data/dataset\u001b[0m\n",
      "\u001b[34mSM_HP_HP1=value_x\u001b[0m\n",
      "\u001b[34mSM_HP_HP3=3.1415\u001b[0m\n",
      "\u001b[34mSM_HP_HP2=314\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python39.zip:/usr/local/lib/python3.9:/usr/local/lib/python3.9/lib-dynload:/usr/local/lib/python3.9/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python train.py --hp1 value_x --hp2 314 --hp3 3.1415\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "2021-05-22 22:43:08 Uploading - Uploading generated training model\n",
      "2021-05-22 22:43:08 Completed - Training job completed\n",
      "\u001b[34mvalue_x\u001b[0m\n",
      "\u001b[34m314\u001b[0m\n",
      "\u001b[34m3.1415\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/dataset\u001b[0m\n",
      "\u001b[34mml/\u001b[0m\n",
      "\u001b[34m├── checkpoints/\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_0.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_1.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_10.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_11.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_12.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_13.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_14.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_15.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_16.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_17.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_2.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_3.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_4.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_5.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_6.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_7.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_8.txt\u001b[0m\n",
      "\u001b[34m│   └── checkpoint_test_9.txt\u001b[0m\n",
      "\u001b[34m├── code/\u001b[0m\n",
      "\u001b[34m│   └── train.py\u001b[0m\n",
      "\u001b[34m├── input/\u001b[0m\n",
      "\u001b[34m│   ├── config/\u001b[0m\n",
      "\u001b[34m│   │   ├── checkpointconfig.json\u001b[0m\n",
      "\u001b[34m│   │   ├── hyperparameters.json\u001b[0m\n",
      "\u001b[34m│   │   ├── init-config.json\u001b[0m\n",
      "\u001b[34m│   │   ├── inputdataconfig.json\u001b[0m\n",
      "\u001b[34m│   │   ├── metric-definition-regex.json\u001b[0m\n",
      "\u001b[34m│   │   ├── profilerconfig.json\u001b[0m\n",
      "\u001b[34m│   │   ├── resourceconfig.json\u001b[0m\n",
      "\u001b[34m│   │   ├── tensorboardoutputconfig.json\u001b[0m\n",
      "\u001b[34m│   │   ├── trainingjobconfig.json\u001b[0m\n",
      "\u001b[34m│   │   └── upstreamoutputdataconfig.json\u001b[0m\n",
      "\u001b[34m│   └── data/\u001b[0m\n",
      "\u001b[34m│       ├── checkpoints-manifest\u001b[0m\n",
      "\u001b[34m│       ├── dataset/\u001b[0m\n",
      "\u001b[34m│       │   ├── ISIC2018_Task1-2_Training_Input/\u001b[0m\n",
      "\u001b[34m│       │   │   ├── ATTRIBUTION.txt\u001b[0m\n",
      "\u001b[34m│       │   │   ├── ISIC_0000000.jpg\u001b[0m\n",
      "\u001b[34m│       │   │   ├── ISIC_0000001.jpg\u001b[0m\n",
      "\u001b[34m│       │   │   ├── ISIC_0000003.jpg\u001b[0m\n",
      "\u001b[34m│       │   │   ├── ISIC_0000004.jpg\u001b[0m\n",
      "\u001b[34m│       │   │   └── ISIC_0000006.jpg\u001b[0m\n",
      "\u001b[34m│       │   └── ISIC2018_Task1_Training_GroundTruth/\u001b[0m\n",
      "\u001b[34m│       │       ├── ATTRIBUTION.txt\u001b[0m\n",
      "\u001b[34m│       │       ├── ISIC_0000000_segmentation.png\u001b[0m\n",
      "\u001b[34m│       │       ├── ISIC_0000001_segmentation.png\u001b[0m\n",
      "\u001b[34m│       │       ├── ISIC_0000003_segmentation.png\u001b[0m\n",
      "\u001b[34m│       │       ├── ISIC_0000004_segmentation.png\u001b[0m\n",
      "\u001b[34m│       │       ├── ISIC_0000006_segmentation.png\u001b[0m\n",
      "\u001b[34m│       │       ├── ISIC_0000007_segmentation.png\u001b[0m\n",
      "\u001b[34m│       │       └── ISIC_0000008_segmentation.png\u001b[0m\n",
      "\u001b[34m│       ├── dataset-manifest\u001b[0m\n",
      "\u001b[34m│       ├── model/\u001b[0m\n",
      "\u001b[34m│       │   └── mask_rcnn_coco.h5\u001b[0m\n",
      "\u001b[34m│       └── model-manifest\u001b[0m\n",
      "\u001b[34m├── model/\u001b[0m\n",
      "\u001b[34m└── output/\n",
      "    ├── data/\n",
      "    ├── metrics/\n",
      "    │   └── sagemaker/\n",
      "    ├── profiler/\n",
      "    │   └── framework/\n",
      "    └── tensorboard/\n",
      "\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 1/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 1/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 2/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 2/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 3/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 3/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 4/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 4/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 5/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 5/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 6/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 6/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 7/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 7/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 8/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 8/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 9/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 9/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 10/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 10/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 11/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 11/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 12/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 12/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 13/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 13/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 14/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 14/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 15/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 15/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 16/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 16/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 17/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 17/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 18/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 18/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 19/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 19/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 20/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 20/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 21/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 21/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 22/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 22/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 23/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 23/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 24/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 24/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 25/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 25/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 26/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 26/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 27/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 27/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 28/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 28/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 29/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 29/10\u001b[0m\n",
      "\u001b[34mnew tensorboard record saved 30/10\u001b[0m\n",
      "\u001b[34mnew checkpoint saved 30/10\u001b[0m\n",
      "\u001b[34mml/\u001b[0m\n",
      "\u001b[34m├── checkpoints/\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_0.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_0.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_1.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_1.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_10.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_10.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_11.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_11.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_12.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_12.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_13.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_13.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_14.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_14.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_15.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_15.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_16.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_16.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_17.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_17.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_18.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_18.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_19.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_19.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_2.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_2.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_20.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_20.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_21.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_21.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_22.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_22.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_23.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_23.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_24.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_24.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_25.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_25.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_26.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_26.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_27.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_27.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_28.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_28.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_29.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_29.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_3.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_3.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_4.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_4.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_5.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_5.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_6.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_6.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_7.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_7.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_8.txt\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_8.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m│   ├── checkpoint_test_9.txt\u001b[0m\n",
      "\u001b[34m│   └── checkpoint_test_9.txt.sagemaker-uploaded\u001b[0m\n",
      "\u001b[34m├── code/\u001b[0m\n",
      "\u001b[34m│   └── train.py\u001b[0m\n",
      "\u001b[34m├── input/\u001b[0m\n",
      "\u001b[34m│   ├── config/\u001b[0m\n",
      "\u001b[34m│   │   ├── checkpointconfig.json\u001b[0m\n",
      "\u001b[34m│   │   ├── hyperparameters.json\u001b[0m\n",
      "\u001b[34m│   │   ├── init-config.json\u001b[0m\n",
      "\u001b[34m│   │   ├── inputdataconfig.json\u001b[0m\n",
      "\u001b[34m│   │   ├── metric-definition-regex.json\u001b[0m\n",
      "\u001b[34m│   │   ├── profilerconfig.json\u001b[0m\n",
      "\u001b[34m│   │   ├── resourceconfig.json\u001b[0m\n",
      "\u001b[34m│   │   ├── tensorboardoutputconfig.json\u001b[0m\n",
      "\u001b[34m│   │   ├── trainingjobconfig.json\u001b[0m\n",
      "\u001b[34m│   │   └── upstreamoutputdataconfig.json\u001b[0m\n",
      "\u001b[34m│   └── data/\u001b[0m\n",
      "\u001b[34m│       ├── checkpoints-manifest\u001b[0m\n",
      "\u001b[34m│       ├── dataset/\u001b[0m\n",
      "\u001b[34m│       │   ├── ISIC2018_Task1-2_Training_Input/\u001b[0m\n",
      "\u001b[34m│       │   │   ├── ATTRIBUTION.txt\u001b[0m\n",
      "\u001b[34m│       │   │   ├── ISIC_0000000.jpg\u001b[0m\n",
      "\u001b[34m│       │   │   ├── ISIC_0000001.jpg\u001b[0m\n",
      "\u001b[34m│       │   │   ├── ISIC_0000003.jpg\u001b[0m\n",
      "\u001b[34m│       │   │   ├── ISIC_0000004.jpg\u001b[0m\n",
      "\u001b[34m│       │   │   └── ISIC_0000006.jpg\u001b[0m\n",
      "\u001b[34m│       │   └── ISIC2018_Task1_Training_GroundTruth/\u001b[0m\n",
      "\u001b[34m│       │       ├── ATTRIBUTION.txt\u001b[0m\n",
      "\u001b[34m│       │       ├── ISIC_0000000_segmentation.png\u001b[0m\n",
      "\u001b[34m│       │       ├── ISIC_0000001_segmentation.png\u001b[0m\n",
      "\u001b[34m│       │       ├── ISIC_0000003_segmentation.png\u001b[0m\n",
      "\u001b[34m│       │       ├── ISIC_0000004_segmentation.png\u001b[0m\n",
      "\u001b[34m│       │       ├── ISIC_0000006_segmentation.png\u001b[0m\n",
      "\u001b[34m│       │       ├── ISIC_0000007_segmentation.png\u001b[0m\n",
      "\u001b[34m│       │       └── ISIC_0000008_segmentation.png\u001b[0m\n",
      "\u001b[34m│       ├── dataset-manifest\u001b[0m\n",
      "\u001b[34m│       ├── model/\u001b[0m\n",
      "\u001b[34m│       │   └── mask_rcnn_coco.h5\u001b[0m\n",
      "\u001b[34m│       └── model-manifest\u001b[0m\n",
      "\u001b[34m├── model/\u001b[0m\n",
      "\u001b[34m└── output/\n",
      "    ├── data/\n",
      "    │   └── tree_result.txt\n",
      "    ├── metrics/\n",
      "    │   └── sagemaker/\n",
      "    ├── profiler/\n",
      "    │   └── framework/\n",
      "    └── tensorboard/\n",
      "        ├── record_test_0.txt\n",
      "        ├── record_test_0.txt.sagemaker-uploaded\n",
      "        ├── record_test_1.txt\n",
      "        ├── record_test_1.txt.sagemaker-uploaded\n",
      "        ├── record_test_10.txt\n",
      "        ├── record_test_10.txt.sagemaker-uploaded\n",
      "        ├── record_test_11.txt\n",
      "        ├── record_test_11.txt.sagemaker-uploaded\n",
      "        ├── record_test_12.txt\n",
      "        ├── record_test_12.txt.sagemaker-uploaded\n",
      "        ├── record_test_13.txt\n",
      "        ├── record_test_13.txt.sagemaker-uploaded\n",
      "        ├── record_test_14.txt\n",
      "        ├── record_test_14.txt.sagemaker-uploaded\n",
      "        ├── record_test_15.txt\n",
      "        ├── record_test_15.txt.sagemaker-uploaded\n",
      "        ├── record_test_16.txt\n",
      "        ├── record_test_16.txt.sagemaker-uploaded\n",
      "        ├── record_test_17.txt\n",
      "        ├── record_test_17.txt.sagemaker-uploaded\n",
      "        ├── record_test_18.txt\n",
      "        ├── record_test_18.txt.sagemaker-uploaded\n",
      "        ├── record_test_19.txt\n",
      "        ├── record_test_19.txt.sagemaker-uploaded\n",
      "        ├── record_test_2.txt\n",
      "        ├── record_test_2.txt.sagemaker-uploaded\n",
      "        ├── record_test_20.txt\n",
      "        ├── record_test_20.txt.sagemaker-uploaded\n",
      "        ├── record_test_21.txt\n",
      "        ├── record_test_21.txt.sagemaker-uploaded\n",
      "        ├── record_test_22.txt\n",
      "        ├── record_test_22.txt.sagemaker-uploaded\n",
      "        ├── record_test_23.txt\n",
      "        ├── record_test_23.txt.sagemaker-uploaded\n",
      "        ├── record_test_24.txt\n",
      "        ├── record_test_24.txt.sagemaker-uploaded\n",
      "        ├── record_test_25.txt\n",
      "        ├── record_test_25.txt.sagemaker-uploaded\n",
      "        ├── record_test_26.txt\n",
      "        ├── record_test_26.txt.sagemaker-uploaded\n",
      "        ├── record_test_27.txt\n",
      "        ├── record_test_27.txt.sagemaker-uploaded\n",
      "        ├── record_test_28.txt\n",
      "        ├── record_test_28.txt.sagemaker-uploaded\n",
      "        ├── record_test_29.txt\n",
      "        ├── record_test_29.txt.sagemaker-uploaded\n",
      "        ├── record_test_3.txt\n",
      "        ├── record_test_3.txt.sagemaker-uploaded\n",
      "        ├── record_test_4.txt\n",
      "        ├── record_test_4.txt.sagemaker-uploaded\n",
      "        ├── record_test_5.txt\n",
      "        ├── record_test_5.txt.sagemaker-uploaded\n",
      "        ├── record_test_6.txt\n",
      "        ├── record_test_6.txt.sagemaker-uploaded\n",
      "        ├── record_test_7.txt\n",
      "        ├── record_test_7.txt.sagemaker-uploaded\n",
      "        ├── record_test_8.txt\n",
      "        ├── record_test_8.txt.sagemaker-uploaded\n",
      "        ├── record_test_9.txt\n",
      "        └── record_test_9.txt.sagemaker-uploaded\n",
      "\u001b[0m\n",
      "\u001b[34m2021-05-22 22:43:01,615 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 673\n",
      "Billable seconds: 269\n",
      "Managed Spot Training savings: 60.0%\n"
     ]
    }
   ],
   "source": [
    "training_test.fit(\n",
    "    inputs      ={\n",
    "        'dataset': dataset_bucket\n",
    "    },\n",
    "    job_name    = job_name,\n",
    "    wait        = True,\n",
    "    logs        = 'All'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23aed6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python369jvsc74a57bd0b19f05f9342924ce7a5103d60a033f2d0ed3b1132f3eb0781eae98efaac103a9",
   "display_name": "Python 3.6.9 64-bit ('tf_1.14.0': virtualenvwrapper)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}